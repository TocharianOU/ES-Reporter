#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Elasticsearch å·¡æ£€å·¥å…· Web åº”ç”¨
æ”¯æŒä¸Šä¼  diagnostic æ–‡ä»¶å¹¶ç”ŸæˆæŠ¥å‘Š
"""

import os
import sys
import tempfile
import shutil
import zipfile
import uuid
import re
from datetime import datetime
from pathlib import Path
from flask import Flask, render_template, request, jsonify, send_file
from werkzeug.utils import secure_filename

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

# å¯¼å…¥æœ¬åœ°æ¨¡å—
from src.report_generator import ESReportGenerator
from src.html_converter import markdown_to_html, create_html_template
from src.i18n import detect_browser_language, i18n

app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 100 * 1024 * 1024  # 100MB æœ€å¤§æ–‡ä»¶å¤§å°

# å…¨å±€å˜é‡å­˜å‚¨ä»»åŠ¡çŠ¶æ€
tasks = {}
reports = {}

# åœ¨æ‰€æœ‰è·¯ç”±å‰æ·»åŠ è°ƒè¯•ä¿¡æ¯
@app.before_request
def log_request_info():
    print(f"Request path: {request.path}")
    print(f"Request url: {request.url}")
    print(f"Request base url: {request.base_url}")

def markdown_to_html(markdown_content):
    """
    å°†Markdownå†…å®¹è½¬æ¢ä¸ºHTML
    ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸“é—¨å¤„ç†å·¡æ£€æŠ¥å‘Šæ ¼å¼
    """
    html = markdown_content
    
    # è½¬ä¹‰HTMLç‰¹æ®Šå­—ç¬¦
    html = html.replace('&', '&amp;')
    html = html.replace('<', '&lt;')
    html = html.replace('>', '&gt;')
    
    # æ ‡é¢˜å¤„ç†
    html = re.sub(r'^### (.*?)$', r'<h3>\1</h3>', html, flags=re.MULTILINE)
    html = re.sub(r'^## (.*?)$', r'<h2>\1</h2>', html, flags=re.MULTILINE)
    html = re.sub(r'^# (.*?)$', r'<h1>\1</h1>', html, flags=re.MULTILINE)
    
    # ç²—ä½“å’Œå¼ºè°ƒ
    html = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', html)
    html = re.sub(r'\*(.*?)\*', r'<em>\1</em>', html)
    
    # ä»£ç å—å¤„ç†
    html = re.sub(r'`([^`]+)`', r'<code>\1</code>', html)
    
    # è¡¨æ ¼å¤„ç†
    lines = html.split('\n')
    result_lines = []
    in_table = False
    table_buffer = []
    
    for line in lines:
        stripped = line.strip()
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯è¡¨æ ¼è¡Œ
        if stripped.startswith('|') and stripped.endswith('|'):
            if not in_table:
                in_table = True
                table_buffer = []
            table_buffer.append(line)
        else:
            # å¦‚æœä¹‹å‰åœ¨è¡¨æ ¼ä¸­ï¼Œç°åœ¨é€€å‡ºè¡¨æ ¼
            if in_table:
                html_table = process_table(table_buffer)
                result_lines.append(html_table)
                in_table = False
                table_buffer = []
            
            # å¤„ç†åˆ—è¡¨
            if stripped.startswith('- '):
                # å¦‚æœå‰ä¸€è¡Œä¸æ˜¯åˆ—è¡¨é¡¹ï¼Œå¼€å§‹æ–°çš„åˆ—è¡¨
                if result_lines and not result_lines[-1].strip().startswith('<li>'):
                    result_lines.append('<ul>')
                
                list_content = stripped[2:].strip()
                result_lines.append(f'<li>{list_content}</li>')
            else:
                # å¦‚æœå‰ä¸€è¡Œæ˜¯åˆ—è¡¨é¡¹ï¼Œå…³é—­åˆ—è¡¨
                if result_lines and result_lines[-1].strip().startswith('<li>'):
                    result_lines.append('</ul>')
                
                result_lines.append(line)
    
    # å¤„ç†æœ€åçš„è¡¨æ ¼
    if in_table and table_buffer:
        html_table = process_table(table_buffer)
        result_lines.append(html_table)
    
    # å¤„ç†æœ€åçš„åˆ—è¡¨
    if result_lines and result_lines[-1].strip().startswith('<li>'):
        result_lines.append('</ul>')
    
    html = '\n'.join(result_lines)
    
    # å¤„ç†æ¢è¡Œå’Œæ®µè½
    html = html.replace('\n\n', '</p><p>')
    html = '<p>' + html + '</p>'
    html = html.replace('<p><h', '<h').replace('</h1></p>', '</h1>')
    html = html.replace('</h2></p>', '</h2>').replace('</h3></p>', '</h3>')
    html = html.replace('<p><table', '<table').replace('</table></p>', '</table>')
    html = html.replace('<p><ul>', '<ul>').replace('</ul></p>', '</ul>')
    html = html.replace('<p></p>', '')
    
    return html

def process_table(table_lines):
    """å¤„ç†è¡¨æ ¼è½¬æ¢"""
    if len(table_lines) < 2:
        return '\n'.join(table_lines)
    
    # ç¬¬ä¸€è¡Œæ˜¯è¡¨å¤´
    header_line = table_lines[0].strip()
    header_cells = [cell.strip() for cell in header_line.split('|')[1:-1]]
    
    # ç¬¬äºŒè¡Œé€šå¸¸æ˜¯åˆ†éš”ç¬¦ï¼Œè·³è¿‡
    data_lines = table_lines[2:] if len(table_lines) > 2 else []
    
    html = ['<table class="table table-striped table-bordered">']
    
    # è¡¨å¤´
    if header_cells:
        html.append('<thead>')
        html.append('<tr>')
        for cell in header_cells:
            html.append(f'<th>{cell}</th>')
        html.append('</tr>')
        html.append('</thead>')
    
    # è¡¨ä½“
    if data_lines:
        html.append('<tbody>')
        for line in data_lines:
            line = line.strip()
            if line.startswith('|') and line.endswith('|'):
                cells = [cell.strip() for cell in line.split('|')[1:-1]]
                html.append('<tr>')
                for cell in cells:
                    html.append(f'<td>{cell}</td>')
                html.append('</tr>')
        html.append('</tbody>')
    
    html.append('</table>')
    return '\n'.join(html)

@app.route('/')
def index():
    """ä¸»é¡µ - æ”¯æŒè¯­è¨€æ£€æµ‹"""
    # æ£€æµ‹æµè§ˆå™¨è¯­è¨€
    accept_language = request.headers.get('Accept-Language', '')
    detected_lang = detect_browser_language(accept_language)
    
    # è®¾ç½®è¯­è¨€
    i18n.set_language(detected_lang)
    
    return render_template('index.html', language=detected_lang)

@app.route('/health')
def health():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'service': 'Elasticsearch å·¡æ£€å·¥å…·',
        'version': '2.0.0',
        'path': request.path
    })

@app.route('/api/upload-diagnostic', methods=['POST'])
def upload_diagnostic():
    """ä¸Šä¼ å¹¶å¤„ç† diagnostic æ–‡ä»¶"""
    try:
        # è·å–è¯­è¨€å‚æ•°
        language = request.form.get('language', 'zh')  # é»˜è®¤ä¸­æ–‡
        if language not in ['zh', 'en']:
            language = 'zh'
        
        # è®¾ç½®å›½é™…åŒ–è¯­è¨€
        i18n.set_language(language)
        
        # æ£€æŸ¥æ–‡ä»¶
        if 'diagnostic_file' not in request.files:
            return jsonify({'success': False, 'message': i18n.t('error_no_file', 'ui')})
        
        file = request.files['diagnostic_file']
        if file.filename == '':
            return jsonify({'success': False, 'message': i18n.t('error_no_file', 'ui')})
        
        if not file.filename.lower().endswith('.zip'):
            return jsonify({'success': False, 'message': i18n.t('error_file_format', 'ui')})
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = tempfile.mkdtemp()
        upload_dir = os.path.join(temp_dir, 'diagnostic')
        
        try:
            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
            filename = secure_filename(file.filename)
            zip_path = os.path.join(temp_dir, filename)
            file.save(zip_path)
            
            # è§£å‹æ–‡ä»¶
            print(f"ğŸ“ è§£å‹è¯Šæ–­æ–‡ä»¶: {filename}")
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(upload_dir)
            
            # æŸ¥æ‰¾å®é™…çš„æ•°æ®ç›®å½•
            data_dir = find_diagnostic_data_dir(upload_dir)
            if not data_dir:
                return jsonify({'success': False, 'message': i18n.t('error_invalid_diagnostic', 'ui')})
            
            print(f"ğŸ“Š å‘ç°è¯Šæ–­æ•°æ®ç›®å½•: {data_dir}")
            
            # ç”ŸæˆæŠ¥å‘Š
            print("ğŸš€ å¼€å§‹ç”ŸæˆæŠ¥å‘Š...")
            report_generator = ESReportGenerator(data_dir, language=language)  # ä¼ é€’è¯­è¨€å‚æ•°
            report_result = report_generator.generate_report(generate_html=True)  # ç”ŸæˆHTMLç‰ˆæœ¬
            
            # è¯»å–æŠ¥å‘Šå†…å®¹
            markdown_path = report_result.get('markdown')
            if not markdown_path or not os.path.exists(markdown_path):
                return jsonify({'success': False, 'message': i18n.t('error_report_failed', 'ui')})
            
            with open(markdown_path, 'r', encoding='utf-8') as f:
                markdown_content = f.read()
            
            # è½¬æ¢ä¸ºHTML
            html_content = markdown_to_html(markdown_content)
            
            # ç”Ÿæˆå”¯ä¸€æŠ¥å‘ŠID
            report_id = str(uuid.uuid4())
            
            # ä¿å­˜æŠ¥å‘Šæ•°æ®
            reports[report_id] = {
                'markdown_content': markdown_content,
                'html_content': html_content,
                'markdown_path': markdown_path,
                'html_path': report_result.get('html'),
                'generated_at': datetime.now().isoformat(),
                'filename': filename,
                'language': language  # ä¿å­˜è¯­è¨€ä¿¡æ¯
            }
            
            print(f"âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ: {report_id}")
            
            return jsonify({
                'success': True,
                'report_id': report_id,
                'report_content': markdown_content,
                'html_content': html_content,
                'generated_at': datetime.now().isoformat(),
                'language': language
            })
            
        except zipfile.BadZipFile:
            return jsonify({'success': False, 'message': i18n.t('error_invalid_zip', 'ui')})
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return jsonify({'success': False, 'message': f'{i18n.t("error_processing", "ui")}: {str(e)}'})
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆä¿ç•™æŠ¥å‘Šæ–‡ä»¶ï¼‰
            try:
                if os.path.exists(zip_path):
                    os.remove(zip_path)
                if os.path.exists(upload_dir):
                    shutil.rmtree(upload_dir)
            except Exception as e:
                print(f"âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
        
    except Exception as e:
        print(f"âŒ ä¸Šä¼ å¤„ç†å¤±è´¥: {e}")
        return jsonify({'success': False, 'message': f'{i18n.t("error_server", "ui")}: {str(e)}'})

def find_diagnostic_data_dir(base_dir):
    """æŸ¥æ‰¾è¯Šæ–­æ•°æ®ç›®å½•"""
    # å¸¸è§çš„è¯Šæ–­æ•°æ®ç›®å½•ç»“æ„
    possible_paths = [
        base_dir,
        os.path.join(base_dir, '*'),  # ç¬¬ä¸€çº§å­ç›®å½•
    ]
    
    # æŸ¥æ‰¾åŒ…å«å…³é”®æ–‡ä»¶çš„ç›®å½•
    key_files = ['cluster_health.json', 'cluster_stats.json', 'nodes_info.json']
    
    def check_directory(dir_path):
        """æ£€æŸ¥ç›®å½•æ˜¯å¦åŒ…å«è¯Šæ–­æ–‡ä»¶"""
        if not os.path.isdir(dir_path):
            return False
        files = os.listdir(dir_path)
        return any(key_file in files for key_file in key_files)
    
    # ç›´æ¥æ£€æŸ¥åŸºç¡€ç›®å½•
    if check_directory(base_dir):
        return base_dir
    
    # æ£€æŸ¥å­ç›®å½•
    try:
        for item in os.listdir(base_dir):
            item_path = os.path.join(base_dir, item)
            if os.path.isdir(item_path) and check_directory(item_path):
                return item_path
    except Exception as e:
        print(f"âš ï¸ æœç´¢è¯Šæ–­ç›®å½•æ—¶å‡ºé”™: {e}")
    
    return None

def generate_download_filename(original_filename: str, report_format: str) -> str:
    """
    åŸºäºåŸå§‹ZIPæ–‡ä»¶åç”Ÿæˆä¸‹è½½æ–‡ä»¶å
    
    Args:
        original_filename: åŸå§‹ZIPæ–‡ä»¶å (å¦‚: diagnostic_data.zip)
        report_format: æŠ¥å‘Šæ ¼å¼ ('html' æˆ– 'md')
    
    Returns:
        ç”Ÿæˆçš„ä¸‹è½½æ–‡ä»¶å (å¦‚: diagnostic_data_report.html)
    """
    # å»æ‰.zipæ‰©å±•å
    base_name = original_filename
    if base_name.lower().endswith('.zip'):
        base_name = base_name[:-4]
    
    # æ·»åŠ æ—¶é—´æˆ³å’Œæ ¼å¼åç¼€
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    return f"{base_name}_report_{timestamp}.{report_format}"

@app.route('/api/download-html/<report_id>')
def download_html(report_id):
    """ä¸‹è½½HTMLæŠ¥å‘Š"""
    if report_id not in reports:
        return jsonify({'error': 'æŠ¥å‘Šä¸å­˜åœ¨'}), 404
    
    report_data = reports[report_id]
    markdown_content = report_data.get('markdown_content')
    
    if not markdown_content:
        return jsonify({'error': 'HTMLå†…å®¹ä¸å­˜åœ¨'}), 404
    
    try:
        # ç”Ÿæˆä¼˜åŒ–çš„HTMLå†…å®¹
        html_content = markdown_to_html(markdown_content)
        full_html = create_html_template(html_content, "Elasticsearch å·¡æ£€æŠ¥å‘Š")
        
        # åˆ›å»ºä¸´æ—¶HTMLæ–‡ä»¶
        import tempfile
        temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False, encoding='utf-8')
        temp_file.write(full_html)
        temp_file.close()
        
        filename = generate_download_filename(report_data['filename'], 'html')
        
        def remove_file(response):
            try:
                os.unlink(temp_file.name)
            except Exception:
                pass
            return response
        
        response = send_file(temp_file.name, as_attachment=True, download_name=filename)
        response.call_on_close(remove_file)
        return response
    except Exception as e:
        return jsonify({'error': f'HTMLä¸‹è½½å¤±è´¥: {str(e)}'}), 500

@app.route('/api/download-markdown/<report_id>')
def download_markdown(report_id):
    """ä¸‹è½½MarkdownæŠ¥å‘Š"""
    if report_id not in reports:
        return jsonify({'error': 'æŠ¥å‘Šä¸å­˜åœ¨'}), 404
    
    report_data = reports[report_id]
    markdown_path = report_data.get('markdown_path')
    
    if not markdown_path or not os.path.exists(markdown_path):
        return jsonify({'error': 'Markdownæ–‡ä»¶ä¸å­˜åœ¨'}), 404
    
    try:
        filename = generate_download_filename(report_data['filename'], 'md')
        return send_file(markdown_path, as_attachment=True, download_name=filename)
    except Exception as e:
        return jsonify({'error': f'Markdownä¸‹è½½å¤±è´¥: {str(e)}'}), 500

@app.route('/api/reports')
def list_reports():
    """åˆ—å‡ºæ‰€æœ‰æŠ¥å‘Š"""
    report_list = []
    for report_id, data in reports.items():
        report_list.append({
            'id': report_id,
            'generated_at': data['generated_at'],
            'filename': data['filename']
        })
    
    return jsonify({
        'success': True,
        'reports': sorted(report_list, key=lambda x: x['generated_at'], reverse=True)
    })

@app.errorhandler(413)
def too_large(e):
    """æ–‡ä»¶è¿‡å¤§å¤„ç†"""
    return jsonify({'success': False, 'message': 'æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶ï¼ˆæœ€å¤§100MBï¼‰'}), 413

@app.errorhandler(404)
def not_found(e):
    """404é”™è¯¯å¤„ç†"""
    return jsonify({'error': 'é¡µé¢ä¸å­˜åœ¨'}), 404

@app.errorhandler(500)
def server_error(e):
    """500é”™è¯¯å¤„ç†"""
    return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500

if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='Elasticsearch å·¡æ£€å·¥å…· Web æœåŠ¡')
    parser.add_argument('--host', default='0.0.0.0', help='ç›‘å¬åœ°å€')
    parser.add_argument('--port', type=int, default=5000, help='ç›‘å¬ç«¯å£')
    parser.add_argument('--debug', action='store_true', help='å¯ç”¨è°ƒè¯•æ¨¡å¼')
    
    args = parser.parse_args()
    
    print("ğŸš€ å¯åŠ¨ Elasticsearch å·¡æ£€å·¥å…· Web æœåŠ¡")
    print(f"ğŸ“ æœåŠ¡åœ°å€: http://{args.host}:{args.port}")
    print("ğŸ’¡ åŠŸèƒ½ç‰¹æ€§:")
    print("   âœ“ ä¸Šä¼  Diagnostic ZIP æ–‡ä»¶")
    print("   âœ“ è‡ªåŠ¨è§£æå’Œåˆ†æ")
    print("   âœ“ ç”Ÿæˆè¯¦ç»†å·¡æ£€æŠ¥å‘Š")
    print("   âœ“ å®æ—¶ HTML é¢„è§ˆ")
    print("   âœ“ Markdown/HTML ä¸‹è½½")
    print()
    
    app.run(host=args.host, port=args.port, debug=args.debug) 